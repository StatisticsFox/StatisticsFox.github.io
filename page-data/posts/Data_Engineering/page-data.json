{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/Data_Engineering","result":{"pageContext":{"currentCategory":"Data_Engineering","categories":["All","Data_Engineering","ERROR","Cloud","Humanities"],"edges":[{"node":{"id":"c8938597-f720-59b3-aeff-05495be9093f","excerpt":"사진\n이번에 카프카를 로컬에서도 돌려보고 클라우드 환경에서도 다뤄보게 되었다. 그래서 카프카의 구조나 기본 개념에 대해 정리를 하고 가야할 필요성을 느꼈다. 물론 실제 구축을 할때는 인프라적인 측면에서 더 애를 먹는다. 방화벽 설정이라던지.. 그래서 기본적인 개념에 대해서는 약간 소홀해 지는 경향이 있었다. 아래 토픽 생성할 때의 shell 명령어를 보자 사실 이 문구를 그냥 copy/paste 한다면야 생성 가능하겠지만 라는 명령어가 어떤 의미인지 잘 모른다면 사실상 kafka를 사용하는 의미가 없다. 때문에 이번 기회에 깊이있게는 아니더라도 대략적으로 정리를 해보려고 한다. Back ground of Kafka Kafka는 왜 Kafka일까? 카프카의 창시자인 Jay Kreps는 kafka는 쓰기에 최적화된 시스템이기에 작가의 이름을 붙이는게 낫다고 생각하여 본인이 좋아하는 작가인 프란츠 카프카의 이름을 오픈소스 프로젝트 이름으로 명명했다. Before Kafka & After…","fields":{"slug":"/Data Engineering/kafka/"},"frontmatter":{"categories":"Data_Engineering","title":"Apache Kafka에 대해 전반적으로 알아보자","date":"April 19, 2024"}},"next":{"fields":{"slug":"/error/"}},"previous":null},{"node":{"id":"c93d6bf6-fd4c-5f6e-9fdf-fc2a218c7715","excerpt":"데이터 파이프라인 최적화의 필요성 대 빅데이터 시대인 만큼 데이터 파이프라인을 최적화하는 것은 굉장히 중요하다. 특히 MLOps 분야에서는 훨씬 더 중요하다. 왜냐하면 AI 성능이 기하급수적으로 발전하면서 그만큼 추론속도나 학습 속도 또한 굉장히 중요해지고 있기 때문이다.\n사진 보편적인 최적화 방안이 존재할까? 그렇다면 데이터 파이프라인을 최적화하는 보편적인 정답이 존재할까? 내 대답은 No!다. 구축하는 파이프라인마다 도메인과 요구사항들이 모두 다르기 때문에 보편적인 요구사항이란 존재할 수 없다.\n사진 보편적인 컴포넌트는 존재할까? 그렇다면 보편적인 컴포넌트는 중요할까? 내 대답은 Yes다. 보편적인 컴포넌트는 존재한다. 바로 DataLake다.\n데이터 파이프라인은 “수집 -> 적재 -> 처리 -> 활용”의 단계를 거치는데 이때 적재 부분에서 실제 데이터를 운영용으로쓰는 경우에는 Datalake를 사용할 수밖에 없다. 따라서 datalake를 최적화 하는것이 결국 데이터 파이프라…","fields":{"slug":"/Data Engineering/DataOptimizations/"},"frontmatter":{"categories":"Data_Engineering","title":"DataOptimizations - Speed up your pipeline","date":"March 17, 2024"}},"next":{"fields":{"slug":"/Data Engineering/index1/"}},"previous":{"fields":{"slug":"/Cloud/"}}},{"node":{"id":"b69e39d6-05a6-5594-938f-c93a25fe0343","excerpt":"제목을 보면 이게 무슨 소리인가 싶을 수 있다. 나도 처음 듣고 띠요옹? 했었다. 내가 알고 있는 MongoDB는 BASE(BA: Basically Avaliable) 즉, 가용성과 성능을 중시한 분산 시스템의 특성을 가지고 있고 또한 이 점이 기존에 ACID 특성을 가진 RDBMS와의 차이점이라고 알고 있었다. 더군다나 Mongo DB가 탄생하게 된 배경이 아래와 같은 고민 끝에 탄생한 것을 알았기에 더욱 의아했었다. 대규모 데이터를 처리해야 하는데 RDBMS는 성장 한계가 있구나 일관성과 무결성을 버리고 더 빠른 읽기 성능과 수평확장이 가능한 DB가 필요해! 그럼 어쩌다 제목과 같이 눈이 크게 떠지는 질문을 스스로에서 던졌을까 이번에 대규모 시스템 설계 기초 도서를 공부하면서 CAP이론이라는 것을 처음 접하며 이 의문이 시작되었다. CAP이론 이란? CAP 이론은 2000년에 에릭 브류어가 최초로 소개한 이론이며 어떤 분산 시스템이더라도 Consistency (일관성), Ava…","fields":{"slug":"/Data Engineering/index1/"},"frontmatter":{"categories":"Data_Engineering","title":"뭐? Mongo DB가 가용성을 보장하지 않는다고?","date":"February 18, 2024"}},"next":{"fields":{"slug":"/Me/index1/"}},"previous":{"fields":{"slug":"/Data Engineering/DataOptimizations/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}