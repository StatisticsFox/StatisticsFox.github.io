{"componentChunkName":"component---src-templates-category-template-js","path":"/posts","result":{"pageContext":{"currentCategory":"All","edges":[{"node":{"id":"65ed6c54-090e-5298-95e0-3f10541b2418","excerpt":"들어가기에 앞서 현재 가독성 수정중..","fields":{"slug":"/Data Engineering/AKS airflow/"},"frontmatter":{"categories":"Data_Engineering","title":"Terraform으로 AKS에 airflow 띄우고 git으로 DAG 관리하기","date":"August 11, 2024"}},"next":{"fields":{"slug":"/Data Engineering/ETL의 T(transform)를 위한 Spark-Streaming 코드 작성하기/"}},"previous":null},{"node":{"id":"86485b27-e91e-508b-8973-c55fb988ce08","excerpt":"들어가기에 앞서.. 요새는 학교 과제를 위한 따릉이 대시보드가 아닌 한이음 ICT 공모전을 위한 따릉이 실시간 대시보드 구축을 진행중이다. 원래는 카프카로 데이터를 producing 하자마자 스피드레이어를 구축해서 대시보드에 마이크로 배치 형태로 실시간 대시보드를 구축했다면 이번에는 대시보드를 더 고도화하기 위해 Spark를 이용해 한번 형태 변환을 하고 S3에 적제하는 과정을 거져봤다. 즉, 아키텍쳐의 변화가 다음과 같다. 이전 아키텍쳐 변경 후 아키텍쳐 좀 많이 힘써봤다. 단순하게 실시간 모니터링만 하는 대시보드는 식상하기도 하고 솔직히 요즘 같이 Chatgpt가 발달한 시대에 그 정도 못만드는 사람 없을 것이다. 다만 이렇게 클라우안에서 다양한 툴과 함께 서비스를 제작한다는 것은 또 다른 개념이라 그 의미가 크다. 나는 위 아키텍쳐에서 카프카로부터 데이터를 실시간으로 받아 SPARK에서 변환 후 S3에 실시간으로 적제하는 Spark-Streaming 코드를 이번에 작성해봤다.…","fields":{"slug":"/Data Engineering/ETL의 T(transform)를 위한 Spark-Streaming 코드 작성하기/"},"frontmatter":{"categories":"Data_Engineering","title":"ETL의 T(transform)를 위한 Spark-Streaming 코드 작성하기","date":"August 03, 2024"}},"next":{"fields":{"slug":"/Data Engineering/Github Actions CI + CodeDeploy로 CICD 구햔하기/"}},"previous":{"fields":{"slug":"/Data Engineering/AKS airflow/"}}},{"node":{"id":"04b54a36-7686-58d7-8470-3e8c40d92d0f","excerpt":"들어가기에 앞서 이번에 AWS EC2를 이용해 NAT instance를 활용해 kafka broker를 구축했다. 이제 producer를 실행하면 자연스럽게 카프카를 사용할 수 있다.(리소스 비용 이슈로 프로듀서 서버를 따로 분리하지 않았다.ㅎㅎ) 다만 producer는 아직 본격적으로 개발한 상태가 아닐뿐더러 나중에 대시보드를 배포할 때 producer를 지속적으로 수정해야 한다. 때문에 계속해서 TEST를 해야 하는데 그 과정이 여간 불편한게 아니다. 매번 Ec2 키고 접속해서 주키퍼랑 카프카 올리고… 아무튼 생각보다 노력을 필요로 한다. 또 Github와 같이 producer의 버전을 관리하고 다른 사람들에게 공유도 용이하게 하기 위해서는 응당 구축해야할 것이 있다. 그것이 바로.. CI/CD다!! Devops의 기본 소양이자 DE라면 당연히 알아야 하는 CI/CD를 구현해보기로 했다. 다행히도 학교에서 젠킨스를 이용한 CI/CD 구현 수업을 들었기에 개념 정도는 꿰고 있었다…","fields":{"slug":"/Data Engineering/Github Actions CI + CodeDeploy로 CICD 구햔하기/"},"frontmatter":{"categories":"Data_Engineering Cloud","title":"Implementing CI/CD with Github Actions CI + AWS CodeDeploy","date":"May 31, 2024"}},"next":{"fields":{"slug":"/Data Engineering/Ddareungi real-time Dashboard architecture/"}},"previous":{"fields":{"slug":"/Data Engineering/ETL의 T(transform)를 위한 Spark-Streaming 코드 작성하기/"}}},{"node":{"id":"e460f12c-078a-55df-b32f-ff41cad6bff4","excerpt":"Base 이번에 한이음의 일환으로 클라우드 환경에서 실시간 따릉이 대시보드를 만들게 되었다. 다만 내 역할이 데이터 엔지니어링 및 인프라에 국한되어 있어 개인적으로 오픈소스를 활용하여 로컬에서 하나를 더 만들어 보려고 한다. 때문에 레퍼런스를 찾던 도중 다음과 같은 글을 발견했다.\nhttps://medium.com/@emergeit/realtime-data-streaming-with-apache-kafka-apache-pinot-apache-druid-and-apache-superset-e67161eb9666 \n2년이 넘은 자료이기는 하지만 내 요구사항을 모두 만족했기에 아주 적합한 래퍼런스였다.\n그럼 이제 시작해보자\n시작해보자 Ddareungi real-time Dashboard architecture Dashboard architecture 위는 내가 수정한 아키텍처다. 신경 쓴 부분은 아래와 같다. Docker는 Superset을 올릴때만 사용하고자 한다. 레퍼런스에서는 모든…","fields":{"slug":"/Data Engineering/Ddareungi real-time Dashboard architecture/"},"frontmatter":{"categories":"Data_Engineering","title":"Realtime data streaming with Apache Kafka, Druid, Superset","date":"April 25, 2024"}},"next":{"fields":{"slug":"/Data Engineering/kafka/"}},"previous":{"fields":{"slug":"/Data Engineering/Github Actions CI + CodeDeploy로 CICD 구햔하기/"}}},{"node":{"id":"c8938597-f720-59b3-aeff-05495be9093f","excerpt":"사진카프카 로고\n이번에 카프카를 로컬에서도 돌려보고 클라우드 환경에서도 다뤄보게 되었다. 그래서 카프카의 구조나 기본 개념에 대해 정리를 하고 가야할 필요성을 느꼈다. 물론 실제 구축을 할때는 인프라적인 측면에서 더 애를 먹는다. 방화벽 설정이라던지.. 그래서 기본적인 개념에 대해서는 약간 소홀해 지는 경향이 있었다. 아래 토픽 생성할 때의 shell 명령어를 보자 사실 이 문구를 그냥 copy/paste 한다면야 생성 가능하겠지만 라는 명령어가 어떤 의미인지 잘 모른다면 사실상 kafka를 사용하는 의미가 없다. 때문에 이번 기회에 깊이있게는 아니더라도 대략적으로 정리를 해보려고 한다. Back ground of Kafka Kafka는 왜 Kafka일까? 카프카의 창시자인 Jay Kreps는 kafka는 쓰기에 최적화된 시스템이기에 작가의 이름을 붙이는게 낫다고 생각하여 본인이 좋아하는 작가인 프란츠 카프카의 이름을 오픈소스 프로젝트 이름으로 명명했다. Before Kafka &…","fields":{"slug":"/Data Engineering/kafka/"},"frontmatter":{"categories":"Data_Engineering","title":"Apache Kafka에 대해 전반적으로 알아보자","date":"April 19, 2024"}},"next":{"fields":{"slug":"/error/"}},"previous":{"fields":{"slug":"/Data Engineering/Ddareungi real-time Dashboard architecture/"}}},{"node":{"id":"a072a1f4-cdc0-5328-a338-4ba99b967d9e","excerpt":"AWS - jammy InRelease & 101: Network is unreachable jammy InRelease 오류 카프카 브로커 Ubuntu 서버에 java를 설치하려고 하는데 아래와 같은 문구가 뜨면서 동작이 되지 않았다. 무슨 jammy가 inrelease된 것 같은데 재미 하나도 없고 머리 아프다 다행히도 해당 에러에 대해서는 AWS측에서 답변 달아준 부분 있다.\n 공식 해결 방법 대충 해석을 보면 아래의 포인트들을 다시 체크해봐라 같은데 해석해보면 다음과 같다. 현재 EC2가 제대로 작동하는 다른 EC2들과 동일한 VPC 및 서브넷에 배포되었는가? 그게 아니라면 VPC가 인터넷 게이트웨이로 인터넷에 접근이 허용되어 있는가? 서브넷이 public이라면 인터넷 바운드 트레픽을 인터넷 게이트 웨이로 라우팅하는 라우팅 테이블이 있는가? 서브넷이 private이라면 인터넷 바운드 트래픽을 공용 서브넷의 NAT 게이트 위에이로 라우팅하는 라우팅 테이블이 있는가? 체크리스트…","fields":{"slug":"/error/"},"frontmatter":{"categories":"ERROR Cloud","title":"AWS - jammy InRelease & 101 Network is unreachable 해결하기","date":"April 16, 2024"}},"next":{"fields":{"slug":"/Cloud/"}},"previous":{"fields":{"slug":"/Data Engineering/kafka/"}}},{"node":{"id":"ad2b72e4-7395-5707-be63-0e9e2ee54d97","excerpt":"NAT 인프라 이번에 실시간 따릉이 대시보드 제작 프로젝트에 데이터 엔지니어 및 인프라로 참여하게 되었다.\n협업 및 배포의 용이성 때문에 클라우드를 이용하기로 결정이 났고 AWS에 EC2에 카프카 클러스터를 구축하고 프로듀서를 개발하기로 하였다.  AWS를 이용한 협업은 처음이기에 세세하게 사전조사를 했는데 첫째로 알게 된 사실은 AWS에서 네트워크를 설계할때 NAT의 사용은 필수적이라는 것이다.  보안상 카프카 클러스터 서버들을 외부에서 접근할 수 없게 해야하기 때문이다.  때문에 VPC 인프라를 구축할때 Public 서브넷과 Private 서브넷을 만들어 그안에 EC2 인스턴스를 두고, Bastion Host를 통해 Public 서브넷에서 Priavate 서브넷으로 접속한 후, NAT Gateway를 통해서 외부 인터넷 소스를 사설망에서 받는 식으로 운용된다.  그만큼 중요한 것으로 당연히 AWS에도 관련 서비스인 NAT Gateway가 존재하고 그것을 이용해서 손쉽게 사설망 …","fields":{"slug":"/Cloud/"},"frontmatter":{"categories":"Cloud","title":"AWS NAT instance를 활용한 비용절약","date":"April 14, 2024"}},"next":{"fields":{"slug":"/Data Engineering/DataOptimizations/"}},"previous":{"fields":{"slug":"/error/"}}},{"node":{"id":"c93d6bf6-fd4c-5f6e-9fdf-fc2a218c7715","excerpt":"데이터 파이프라인 최적화의 필요성 대 빅데이터 시대인 만큼 데이터 파이프라인을 최적화하는 것은 굉장히 중요하다. 특히 MLOps 분야에서는 훨씬 더 중요하다. 왜냐하면 AI 성능이 기하급수적으로 발전하면서 그만큼 추론속도나 학습 속도 또한 굉장히 중요해지고 있기 때문이다.\n사진 보편적인 최적화 방안이 존재할까? 그렇다면 데이터 파이프라인을 최적화하는 보편적인 정답이 존재할까? 내 대답은 No!다. 구축하는 파이프라인마다 도메인과 요구사항들이 모두 다르기 때문에 보편적인 요구사항이란 존재할 수 없다.\n사진 보편적인 컴포넌트는 존재할까? 그렇다면 보편적인 컴포넌트는 중요할까? 내 대답은 Yes다. 보편적인 컴포넌트는 존재한다. 바로 DataLake다.\n데이터 파이프라인은 “수집 -> 적재 -> 처리 -> 활용”의 단계를 거치는데 이때 적재 부분에서 실제 데이터를 운영용으로쓰는 경우에는 Datalake를 사용할 수밖에 없다. 따라서 datalake를 최적화 하는것이 결국 데이터 파이프라…","fields":{"slug":"/Data Engineering/DataOptimizations/"},"frontmatter":{"categories":"Data_Engineering","title":"DataOptimizations - Speed up your pipeline","date":"March 17, 2024"}},"next":{"fields":{"slug":"/Data Engineering/index1/"}},"previous":{"fields":{"slug":"/Cloud/"}}},{"node":{"id":"b69e39d6-05a6-5594-938f-c93a25fe0343","excerpt":"제목을 보면 이게 무슨 소리인가 싶을 수 있다. 나도 처음 듣고 띠요옹? 했었다. 내가 알고 있는 MongoDB는 BASE(BA: Basically Avaliable) 즉, 가용성과 성능을 중시한 분산 시스템의 특성을 가지고 있고 또한 이 점이 기존에 ACID 특성을 가진 RDBMS와의 차이점이라고 알고 있었다. 더군다나 Mongo DB가 탄생하게 된 배경이 아래와 같은 고민 끝에 탄생한 것을 알았기에 더욱 의아했었다. 대규모 데이터를 처리해야 하는데 RDBMS는 성장 한계가 있구나 일관성과 무결성을 버리고 더 빠른 읽기 성능과 수평확장이 가능한 DB가 필요해! 그럼 어쩌다 제목과 같이 눈이 크게 떠지는 질문을 스스로에서 던졌을까 이번에 대규모 시스템 설계 기초 도서를 공부하면서 CAP이론이라는 것을 처음 접하며 이 의문이 시작되었다. CAP이론 이란? CAP 이론은 2000년에 에릭 브류어가 최초로 소개한 이론이며 어떤 분산 시스템이더라도 Consistency (일관성), Ava…","fields":{"slug":"/Data Engineering/index1/"},"frontmatter":{"categories":"Data_Engineering","title":"뭐? Mongo DB가 가용성을 보장하지 않는다고?","date":"February 18, 2024"}},"next":{"fields":{"slug":"/Me/index1/"}},"previous":{"fields":{"slug":"/Data Engineering/DataOptimizations/"}}},{"node":{"id":"ddf0ca2c-eac3-579d-948a-a3830b83ae30","excerpt":"행복에 대해서 오늘은 내가 짧게나마 ‘행복’이란 무엇일까에 대해 고민한 내용을 공유할까 한다. 최근에 인문학을 공부하면서 나에게 적용하는 등 여러가지 생각을 하고 있다. 예전에 ‘불안’(아직 글은 안썼음)에 대해서 정의를 해봤는데 이제는 행복에 대해서도 깊게 생각해보고 싶어서 “최근에는 행복이란 무엇일까”에 대해서 고민을 해보았다. 나는 언제 행복할까 그렇다면 나는 언제 행복할까, 궁극적으로 행복에 대해서 정의하기 이전에 단순하게 나는 언제 행복한지에 대해 고민해봤다. 나는 아래와 같은 상황일때 행복을 느꼈던 것 같다. 하루를 다 마치고 친구들이랑 게임할때 평일에 늦잠잘때 사람 많이 없을때 맛집 가서 맛있는거 먹을때 분위기 좋은 카페가서 여유롭게 책을 읽을때 새로운  사람을 만나서 이야기를 공유할때 아주 평범하고 누구나 특별히 게임을 안좋아한다거나 하는게 아닌 이상 대부분 행복을 느낄 것이라고 생각한다. 때문에 일반화하고 정의하기가 막막했는데 내가 예전에 불안에 대해서 생각했던 것…","fields":{"slug":"/Me/index1/"},"frontmatter":{"categories":"Humanities","title":"행복에 대해서 고민해 보았다.","date":"January 10, 2024"}},"next":null,"previous":{"fields":{"slug":"/Data Engineering/index1/"}}}],"categories":["All","Data_Engineering","Cloud","ERROR","Humanities"]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}